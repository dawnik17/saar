{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip install --disable-pip-version-check \\\n",
    "#     torch==1.13.1 \\\n",
    "#     torchdata==0.5.1 --quiet\n",
    "\n",
    "# %pip install \\\n",
    "#     transformers==4.27.2 \\\n",
    "#     datasets==2.11.0 \\\n",
    "#     evaluate==0.4.0 \\\n",
    "#     rouge_score==0.1.2 \\\n",
    "#     loralib==0.1.1 \\\n",
    "#     peft==0.3.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 29 06:32:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:0C:00.0 Off |                  Off |\n",
      "| 30%   34C    P2    65W / 300W |   2481MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:0D:00.0 Off |                  Off |\n",
      "| 30%   25C    P8    31W / 300W |   3899MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000    Off  | 00000000:0E:00.0 Off |                  Off |\n",
      "| 30%   24C    P8    20W / 300W |      8MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000    Off  | 00000000:0F:00.0 Off |                  Off |\n",
      "| 30%   23C    P8    14W / 300W |      8MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-09-03 13:23:19.573288: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-03 13:23:21.056797: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-03 13:23:21.056953: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-03 13:23:21.056969: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (AutoModelForSeq2SeqLM, \n",
    "                          AutoTokenizer, \n",
    "                          GenerationConfig, \n",
    "                          TrainingArguments, \n",
    "                          Trainer)\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  \n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/qblocks/.local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qblocks/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "def load_base_model(model_path=\"google/flan-t5-base\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        model_path, torch_dtype=torch.bfloat16\n",
    "    ).to(device)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_from_peft_adapter(\n",
    "    base_model_path, peft_model_path, train=False, merge_adapter=True\n",
    "):\n",
    "    model, tokenizer = load_base_model(base_model_path)\n",
    "    model = PeftModel.from_pretrained(\n",
    "        model, peft_model_path, torch_dtype=torch.bfloat16, is_trainable=train\n",
    "    ).to(device)\n",
    "\n",
    "    if merge_adapter:\n",
    "        model = model.merge_and_unload()\n",
    "\n",
    "        if train:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    # merge the adapter to the main model\n",
    "    return model, tokenizer\n",
    "\n",
    "def save_peft_adapter(model, model_path):\n",
    "    model.save_pretrained(model_path)\n",
    "\n",
    "def merge_peft_and_save(model, model_path):\n",
    "    model = model.merge_and_unload()\n",
    "    model.save_pretrained(model_path)\n",
    "\n",
    "def save_tokenizer(tokenizer):\n",
    "    tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PeftModel:\n",
    "#     @staticmethod\n",
    "#     def load_base_model(model_path=\"google/flan-t5-base\"):\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "#             model_path, torch_dtype=torch.bfloat16\n",
    "#         ).to(device)\n",
    "#         tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "#         return model, tokenizer\n",
    "\n",
    "#     @staticmethod\n",
    "#     def load_from_peft_adapter(\n",
    "#         base_model_path, peft_model_path, train=False, merge_adapter=True\n",
    "#     ):\n",
    "#         model, tokenizer = self.load_base_model(base_model_path)\n",
    "#         model = PeftModel.from_pretrained(\n",
    "#             model, peft_model_path, torch_dtype=torch.bfloat16, is_trainable=train\n",
    "#         ).to(device)\n",
    "\n",
    "#         if merge_adapter:\n",
    "#             model = model.merge_and_unload()\n",
    "\n",
    "#             if train:\n",
    "#                 for param in model.parameters():\n",
    "#                     param.requires_grad = True\n",
    "\n",
    "#         # merge the adapter to the main model\n",
    "#         return model, tokenizer\n",
    "\n",
    "#     @staticmethod\n",
    "#     def save_peft_adapter(model, model_path):\n",
    "#         model.save_pretrained(model_path)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def merge_peft_and_save(model, model_path):\n",
    "#         model = model.merge_and_unload()\n",
    "#         model.save_pretrained(model_path)\n",
    "        \n",
    "#     @staticmethod\n",
    "#     def save_tokenizer(tokenizer):\n",
    "#         tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old load original model\n",
    "# name='google/flan-t5-base'\n",
    "# model, tokenizer = PeftModel.load_base_model(model_path=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original model\n",
    "name='google/flan-t5-base'\n",
    "model, tokenizer = load_base_model(model_path=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='1.2'></a>\n",
    "### 1.2 - Load Dataset and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inshorts_scraped.json\n"
     ]
    }
   ],
   "source": [
    "# load and aggregate raw data\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Specify the folder path containing the JSON files\n",
    "folder_path = './data'\n",
    "\n",
    "# Initialize an empty list to aggregate the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json') and \"shorts\" in filename:\n",
    "        print(filename)\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read and parse JSON data from the file\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            file_data = json.load(json_file)\n",
    "            \n",
    "            # Assuming each JSON file contains a list of dictionaries\n",
    "            if isinstance(file_data, list):\n",
    "                data.extend(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Man accused of sexually assaulting daughter granted bail by HC amid matrimonial dispute',\n",
       " 'summary': 'Delhi HC granted bail to a man accused of sexually assaulting his daughter, noting that it cannot shut its eyes to matrimonial dispute between her parents and his false implication by \"tutoring\" cannot be ruled out. It observed she has been residing with the mother for over four years. The court also noted there was inordinate delay in FIR registration.',\n",
       " 'link': 'https://www.outlookindia.com/national/delhi-hc-grants-bail-to-man-accused-of-sexually-assaulting-daughter-news-311110/amp?utm_campaign=fullarticle&utm_medium=referral&utm_source=inshorts',\n",
       " 'image_link': 'https://static.inshorts.com/inshorts/images/v1/variants/jpg/m/2023/08_aug/16_wed/img_1692206351958_642.jpg?',\n",
       " 'source': 'inshorts',\n",
       " 'full_text': 'Delhi HC Grants Bail To Man Accused Of Sexually Assaulting Daughter Justice Vikas Mahajan observed the girl has been residing with the mother for more than 4 years and there was an inordinate delay in the registration of the FIR. Delhi High Court The Delhi High Court has granted bail to a man accused of sexually assaulting his daughter while noting that it cannot shut its eyes to the matrimonial dispute between the girl’s parents and his false implication by \"tutoring\" cannot be ruled out. Justice Vikas Mahajan observed the girl has been residing with the mother for more than 4 years and there was an inordinate delay in the registration of the FIR. It noted there were many cross FIRs from the mother\\'s as well as the father\\'s side and \"there is not an iota of reference\" to the alleged incidents of sexual assault in the earlier complaints by the mother. \"Undisputedly, the allegations are serious, but this court cannot shut its eyes to the fact that there is a matrimonial dispute pending between the victim’s parents...In this factual backdrop, false implication of the petitioner by the complainant by tutoring the minor girl child who is in complainant’s custody, cannot be ruled out,\" said the court in a recent order. \"I am prima facie of the view that the above factors have the potential of creating dent in the case of the prosecution,\" the court said. The petitioner father, while seeking bail, told the court there was martial discord between him and his wife, and while the girl aged about 15 years was residing with her mother, a minor son of 10 years was in his care and custody. He alleged his wife was living with a police officer who was helping her file frivolous and bogus complaints against the petitioner. The petitioner was arrested on February 21 and sent to judicial custody. Noting that the incidents alleged occurred in 2019-2022, the complaint was made for the first time only in 2023, the court said that \"evidently, there is an inordinate delay in the registration of FIR\". The court observed the objective of keeping a person in custody is to ensure his availability to face the trial and to receive the sentence that may be awarded and that detention is not supposed to be a punitive or preventive measure. The accused cannot be kept in custody for an indefinite period if trial is not likely to be concluded within reasonable time, it said. In the present case, the court said, the investigation is complete and charge-sheet has been filed but the conclusion of trial was likely to take time. \"In the given circumstances, no useful purpose will be served in keeping the petitioner behind bars...Accordingly, the petitioner is admitted to bail subject to his furnishing a Personal Bond in the sum of Rs.25,000/- and one Surety Bond of the like amount subject to the satisfaction of the Trial Court / Jail Superintendent/Duty Magistrate,\" ordered the court. The court asked the petitioner to not communicate with or establish contact with the alleged victim or witnesses. -With PTI Input',\n",
       " 'createdAt': nan}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# curate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22477"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data = [news for news in data if news[\"full_text\"] != \"\" and \"JavaScript is not available\" not in news[\"full_text\"] and \"reuters\" not in news[\"link\"]]\n",
    "random.shuffle(data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for news in data:\n",
    "    if \"<p>\" in news[\"summary\"]:\n",
    "        # Regular expression to match content between <p> tags\n",
    "        pattern = re.compile(r'<p>(.*?)</p>', re.DOTALL)\n",
    "        matches = pattern.findall(news[\"summary\"])\n",
    "\n",
    "        # Extracted content from <p> tags\n",
    "        extracted_content = [re.sub(r'<.*?>', '', match) for match in matches]\n",
    "        news[\"summary\"] = max(extracted_content, key=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for news in data:   \n",
    "            # input_prompt, label = self._get_summary_prompt(news)\n",
    "            # self.inputs.append(input_prompt)\n",
    "            # self.labels.append(label)\n",
    "            \n",
    "            input_prompt, label = self._get_title_prompt(news)\n",
    "            self.inputs.append(input_prompt)\n",
    "            self.labels.append(label)\n",
    "            \n",
    "        \"\"\"\n",
    "        Combine the lists using zip\n",
    "        Shuffle the combined list\n",
    "        Unpack the shuffled pairs back into separate lists\n",
    "        And then tokenize\n",
    "        \"\"\"\n",
    "        combined = list(zip(self.inputs, self.labels))\n",
    "        random.shuffle(combined)\n",
    "        self.inputs, self.labels = zip(*combined)\n",
    "\n",
    "        # tokenize\n",
    "        self.inputs = tokenizer(self.inputs, \n",
    "                                padding=\"max_length\", \n",
    "                                truncation=True, \n",
    "                                return_tensors=\"pt\").input_ids\n",
    "\n",
    "        self.labels = tokenizer(self.labels, \n",
    "                                padding=\"max_length\", \n",
    "                                truncation=True, \n",
    "                                return_tensors=\"pt\").input_ids\n",
    "            \n",
    "    def __len__(self): \n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        return self.inputs[idx], self.labels[idx]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_summary_prompt(example):\n",
    "        # word count round off\n",
    "        multiple = 25\n",
    "        word_count = len(example[\"summary\"].split())\n",
    "        word_count = int(round(word_count / multiple)) * multiple\n",
    "        \n",
    "        start_prompt = f'Summarize this news article in {word_count} words.\\n\\n'\n",
    "        end_prompt = '\\n\\nSummary: '\n",
    "\n",
    "        prompt = start_prompt + example[\"full_text\"] + end_prompt\n",
    "\n",
    "        return prompt, example[\"summary\"]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_title_prompt(example):\n",
    "        # word count round off\n",
    "        multiple = 5\n",
    "        word_count = len(example[\"title\"].split())\n",
    "        word_count = int(ceil(word_count / multiple)) * multiple\n",
    "        \n",
    "        start_prompt = f'Give a title to the given news article in not more than {word_count} words.\\n\\n'\n",
    "        mid_prompt = '\\n\\nSummary: '\n",
    "        end_prompt = '\\n\\nTitle: '\n",
    "\n",
    "        prompt = start_prompt + example[\"full_text\"] + mid_prompt + example[\"summary\"] + end_prompt\n",
    "        return prompt, example[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TextDataset(data, tokenizer)\n",
    "# test_data = TextDataset(data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6434,     3,     9,  2233,    12,     8,   787,  1506,  1108,    16,\n",
       "            59,    72,   145,   627,  1234,     5,  1547,    43,  2031,  3030,\n",
       "            12,  3197,    80,   223,    16,     8,   874,    18, 19515,   332,\n",
       "          1755,   196,   939,   227,   352,     3,   632,  4949,   323,   778,\n",
       "            16,     8,  2101,   192,  1031,     5,   461,  2818,     6,    44,\n",
       "             8,   337,  5669,   116,    79,  8151,    70,   511,  2541,  1453,\n",
       "             6,  1547,  3030,    12,  4943,    46,  8943,   547,   447,  2391,\n",
       "            18,  5981,    15,    17,  1369,   213,  3705,    63, 16296,  1635,\n",
       "          4701,    26,     9,   208,     3, 25202,    15,    26,   223,    12,\n",
       "           607,    16,   869,    12,   428,     3,     9, 15937,    13,   112,\n",
       "            20,   900, 11026,   200,    16,     8,  1910,     5,   978, 22716,\n",
       "          7673,    13,     3,  4591,  3154,   326,  8537, 11607,  2139,  1547,\n",
       "         15389,   323,     8,  2387,    13, 11321,    28,  1179, 11607,  8179,\n",
       "             5,   299,     3,    88,  2088,    31,    17,     8,  4199,  1053,\n",
       "          1187,     8,  1369,     5,  5209,   332,   173,  1639,   584, 12764,\n",
       "             6,   113,    65,   118,     8,   163,  1465,    45,  1547,    31,\n",
       "             7,   332,  1755,   196,   939,   581,  1244,    86,  7719,     6,\n",
       "          2925,   112, 25781,   607,    12,  2604,    46,    73, 17349,  9526,\n",
       "             5,   611,     6,  2675,   130,   646, 11349,    53,    44,     8,\n",
       "           414,    13,     8,  3805,  1369,    38,    79,  7774, 14268,  3504,\n",
       "         23692,   276,   232,    63,     9,    21,   112,    96, 27826,    11,\n",
       "         12447,   924,   121,  1810,    12,   177,    63,     8,  1021,  1370,\n",
       "             3,     9,   168,    18, 21348,   511, 12096, 18358,    16,     8,\n",
       "           939,     5,   332,   173,  1639,   584, 12764,  4743,   448,    61,\n",
       "            11,  3504, 23692,   276,   232,    63,     9,    41,   448,   201,\n",
       "            13,  1547,     6,   227,  3447,     8,  1025,   332,  1755,   196,\n",
       "         18096,  1588,   344,  1547,    11,  1244,    86,  7719,    44,  2846,\n",
       "         21247,   868,  1061,    16, 29218,     6,  2846, 21247,   599, 26487,\n",
       "            61,     3,     2, 10041, 25252, 22573,     2,     3,     2,    87,\n",
       "         10041, 25252, 22573,     2,     3,     2, 10041, 25252, 22573,     2,\n",
       "             3,     2,    87, 10041, 25252, 22573,     2, 14490,   112,   194,\n",
       "           139,     8,  1547, 12025,    30,     8,   223,    13,   192, 22716,\n",
       "          9385,    21, 15810,  2557,     7,    16,    27,  5329,     6,   332,\n",
       "           173,  1639,    47, 14014,   112,  1038,  5695,    16,     8,   166,\n",
       "          1588,    13,     8,   332,  1755,   196,   939,   213,     3,    88,\n",
       "          5799,    46,  4423,   944,    18,  3184,  6352,     6,     8,   200,\n",
       "          2604,    57,    46,  2557, 15839,    16,     8,  1588,    16,    46,\n",
       "          2904, 12082,     3, 27759,   504,    45,     8,   372,     5,   216,\n",
       "           258,   856,    15,    26,   112,   821,    28,     3,     9,   187,\n",
       "           537,   332,  1755,   196, 18358,    16,     8,   511,   467,    30,\n",
       "             8,     3,     7,    40, 13917,  1273,  2846, 21247,  6242,     5,\n",
       "           461,  2818,     6,     3,    88,     3,  3834,  3510,  3705,    63,\n",
       "         16296,  1635,    16,     3,     9,  1588,    18,    60,  7003,    53,\n",
       "             3,  4225,    18,  4312,  1518,    21,     8,  1025, 29719,   274,\n",
       "             3,    17,    15,    15,    53,   326,    28,   662, 11814,    11,\n",
       "             3,     9,  1296,    12,  2604,    46,    73, 17349,  9526,   326,\n",
       "          6862,     5,    86,   685,     3,    88,  2299,   824,    12,  2604,\n",
       "             3,     9,   511, 12096, 18358,    16,     8,   939,     6,   274,\n",
       "          2684,    53,   323,  1587,     8,   414,    13,  1547,    31,     7,\n",
       "         15389,     5,     3,     2, 10041, 25252, 22573,     2,     3,     2,\n",
       "            87, 10041, 25252, 22573,     2,     3,     2, 10041, 25252, 22573,\n",
       "             2,     1]),\n",
       " tensor([ 3504, 23692,   276,   232,    63,     9, 25669,    15,     7,  1296,\n",
       "            12,   177,    63,   332,   173,  1639,     3,     9,  1253,    12,\n",
       "          1560, 18358,     6,  2675,  8922,     1,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 247577856\n",
      "all model parameters: 247577856\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    \n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        \n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    \n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FULL MODEL TRAINING\n",
    "# EPOCH = 1\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#                                   save_steps=5000,\n",
    "#                                   warmup_steps=10,\n",
    "#                                   logging_steps=100,\n",
    "#                                   weight_decay=0.01,\n",
    "#                                   num_train_epochs=EPOCH,\n",
    "#                                   logging_dir='./logs',\n",
    "#                                   output_dir='./checkpoint',\n",
    "#                                   per_device_eval_batch_size=32,\n",
    "#                                   per_device_train_batch_size=32)\n",
    "\n",
    "# Trainer(model=model,\n",
    "#         args=training_args,\n",
    "#         eval_dataset=test_data,\n",
    "#         train_dataset=train_data,\n",
    "#         data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]), \n",
    "#                                     'labels': torch.stack([f[1] for f in data])}).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 3538944\n",
      "all model parameters: 251116800\n",
      "percentage of trainable model parameters: 1.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28100' max='28100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28100/28100 2:42:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.089200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.087100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.086200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.085400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.084500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.083900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.083600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.083600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.082300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.081500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.081400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.081700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=28100, training_loss=0.23320891139346087, metrics={'train_runtime': 9754.7113, 'train_samples_per_second': 23.042, 'train_steps_per_second': 2.881, 'total_flos': 1.5635652772626432e+17, 'train_loss': 0.23320891139346087, 'epoch': 10.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PEFT MODEL TRAINING\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "\n",
    "EPOCH = 10\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "# peft_model = torch.nn.DataParallel(peft_model)\n",
    "print(print_number_of_trainable_model_parameters(peft_model))\n",
    "\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "                                  # save_steps=5000,\n",
    "                                  save_strategy=\"no\",\n",
    "                                  warmup_steps=10,\n",
    "                                  logging_steps=1000,\n",
    "                                  weight_decay=0.01,\n",
    "                                  num_train_epochs=EPOCH,\n",
    "                                  logging_dir='./logs',\n",
    "                                  output_dir='./checkpoint',\n",
    "                                  learning_rate=0.0001,\n",
    "                                  auto_find_batch_size=True)\n",
    "    \n",
    "peft_trainer = Trainer(\n",
    "                model=peft_model,\n",
    "                args=peft_training_args,\n",
    "                train_dataset=train_data,\n",
    "                data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]), \n",
    "                                            'labels': torch.stack([f[1] for f in data])})\n",
    "\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old save peft adapter\n",
    "# adapter_path = \"./checkpoint/adapter/\"\n",
    "# PeftModel.save_peft_adapter(model=peft_model, model_path=adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old merge peft with main model\n",
    "# # and save the model\n",
    "# model_path = \"./checkpoint/\"\n",
    "# PeftModel.merge_peft_and_save(model=peft_model, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save peft adapter\n",
    "adapter_path = \"./checkpoint/title_adapter/\"\n",
    "save_peft_adapter(model=peft_model, model_path=adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge peft with main model\n",
    "# and save the model\n",
    "model_path = \"./checkpoint/\"\n",
    "merge_peft_and_save(model=peft_model, model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pretrained flan t5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old load original model\n",
    "# model_name='google/flan-t5-base'\n",
    "# original_model, original_tokenizer = PeftModel.load_base_model(model_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original model\n",
    "model_name='google/flan-t5-base'\n",
    "original_model, original_tokenizer = load_base_model(model_path=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the saved peft inshorts model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"./checkpoint/\"\n",
    "# peft_model, tokenizer = PeftModel.load_base_model(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./checkpoint/adapter/\"\n",
    "peft_model, tokenizer = load_from_peft_adapter(model_name, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "FULL TEXT:\n",
      "Please enable Javascript to watch this video \n",
      "  \n",
      " Grainy, poor-quality surveillance footage showing the slow gait of a large cat-like animal walking along a street in densely populated Norwalk has created a mystery. \n",
      "  \n",
      " At first, the person who saw the animal early Tuesday thought it was a mountain lion, but that theory has been discounted by state wildlife officials, City Manager Jeff Hobbs said Friday afternoon. \n",
      "  \n",
      " The California Department of Fish and Wildlife's \"undisputed expert\" determined the animal shown in the video is not a cougar, Hobbs wrote in an email headlined \"'That's No Mountain Lion,' Says CA Dept Fish & Wildlife Expert.\" \n",
      "  \n",
      " \"Department officials still cannot definitively identify the type of animal. They will continue to investigate,\" Hobbs wrote. \n",
      "  \n",
      " A mountain lion sighting was reported about 3:45 a.m. in the 11000 block of Tina Street (map), according to a Los Angeles County Sheriff's Department lieutenant. That's the time shown in the video footage, dated Tuesday. \n",
      "  \n",
      " The densely populated residential area not far from the junction of the 5 and 605 freeways is some 20 miles from typical foothill mountain lion habitat. \n",
      "  \n",
      " The footage, which shows an animal with a large, curving tail, was posted on the city's Facebook page Friday. \n",
      "  \n",
      " A lion expert told the Los Angeles Times the animal in the footage resembled an African lion. \n",
      "  \n",
      " State game warden Don Nelson, who examined the video for the state wildlife department along with predator ecologist Becky Pierce, told the Times he thought the video showed a \"large older dog, maybe a pit bull or part pit bull.\" \n",
      "  \n",
      " A representative of the California Department of Fish and Wildlife visited the neighborhood where the animal was spotted to speak to residents about what to do if they see the animal again, Hobb said. \n",
      "  \n",
      " Sheriff's Department patrol was elevated in the area, he added. ||||| Is it a lion? \n",
      "  \n",
      " A dog? \n",
      "  \n",
      " A Chupacabra? \n",
      "  \n",
      " Residents in Norwalk, California, are jittery over reports of an African lion possibly roaming the streets. \n",
      "  \n",
      " So far, only grainy security images of the mysterious creature have emerged, showing the animal prowling along the sidewalk. \n",
      "  \n",
      " California Department of Fish and Wildlife experts studied that footage. The cat-like animal is not a mountain lion, authorities determined. \n",
      "  \n",
      " “Department officials still cannot definitively identify the type of animal,” authorities said. “They will continue to investigate.” \n",
      "  \n",
      " Norwalk Mayor Marcel Rodarte is intrigued by the creature’s appearance. \n",
      "  \n",
      " “The tail doesn’t seem to match up to the physical traits of a mountain lion, so it is still a mystery,” Rodarte said. \n",
      "  \n",
      " Authorities with a local zoo claimed all the big cats are accounted for. \n",
      "  \n",
      " A similar lion scare occurred last year in Virginia -- but that ominous animal turned out to be a bizarrely-coiffed labradoodle named Charles the Monarch. While dog-grooming tricks can confuse people from time to time, the gait of the mystery beast in California has residents concerned. \n",
      "  \n",
      " “We’ve got dogs and my sister got another little dog, so we’re all just making sure everybody keeps their pets inside,” resident Elizabeth Colon said. |||||\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "– Surveillance video of ... something ... strolling around Norwalk, California, is becoming the city's \"version of Bigfoot,\" reports the LA Times. State officials don't think the creature in the grainy video is a mountain lion, reports KTLA, but they're not hazarding a guess about what it might be. Among the possibilities getting tossed around: an African lioness, a big pit bull, a leopard, or some kind of big-cat hybrid. \"It's still a mystery,\" the mayor tells ABC News. The animal was captured on video walking across somebody's driveway at 3:44am. \"If a lion is out there like that, it shouldn't be happening,\" says the director of a local big-cat sanctuary. (The hunt for Bigfoot isn't going so well, either.)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ORIGINAL MODEL:\n",
      "– A mystery lion has been spotted in Norwalk, Calif., and officials aren't sure what it is. The animal appears to be a mountain lion, but the city manager says the animal isn't a mountain lion. \"Department officials still cannot definitively identify the type of animal,\" the city manager says. \"They will continue to investigate.\" The animal appears to be a lion, but the city manager says the animal isn't a mountain lion. The animal appears to be a dog, and the city manager says the animal isn't a mountain lion. The animal appears to be a chimpanzee, but the city manager says the animal isn't a mountain lion. The animal appears to be a lion, but the city manager says the animal isn't a cougar. The animal appears to be a\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL: – It's not a mountain lion, but a cat-like animal in Norwalk, Calif., has been spotted walking along a sidewalk in the city's densely populated residential area, the Los Angeles Times reports. A lion expert tells the Los Angeles Times the animal in the video resembled an African lion. State game warden Don Nelson, who examined the video for the state wildlife department along with predator ecologist Becky Pierce, said the video showed a \"large older dog, maybe a pit bull or part pit bull.\" A representative of the California Department of Fish and Wildlife visited the neighborhood where the animal was spotted to speak to residents about what to do if they see the animal again. \"We’ve got dogs and my sister got another little dog, so we’re all just making sure everybody keeps their pets inside,\" Norwalk Mayor Marcel Rodarte tells the Los Angeles Times\n",
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.2954545454545454, 'rouge2': 0.06870229007633587, 'rougeL': 0.19696969696969696, 'rougeLsum': 0.19696969696969696}\n",
      "INSTRUCT MODEL:\n",
      "{'rouge1': 0.4028776978417266, 'rouge2': 0.09420289855072464, 'rougeL': 0.1798561151079137, 'rougeLsum': 0.1798561151079137}\n"
     ]
    }
   ],
   "source": [
    "dash_line = '-'.join('' for x in range(100))\n",
    "\n",
    "index = 1000\n",
    "news = data[index]\n",
    "full_text = news['full_text']\n",
    "baseline_human_summary = news['summary']\n",
    "\n",
    "# word count round off\n",
    "multiple = 25\n",
    "word_count = len(baseline_human_summary.split())\n",
    "word_count = int(round(word_count / multiple)) * multiple\n",
    "\n",
    "start_prompt = f'Summarize this news article in {word_count} words.\\n\\n'\n",
    "end_prompt = '\\n\\nSummary: '\n",
    "\n",
    "prompt = start_prompt + full_text + end_prompt\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "original_model_text_output = original_tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=4))\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(dash_line)\n",
    "print(f'FULL TEXT:\\n{full_text}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{baseline_human_summary}')\n",
    "print(dash_line)\n",
    "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL: {peft_model_text_output}')\n",
    "\n",
    "\n",
    "# EVALUATE\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=[original_model_text_output],\n",
    "    references=[baseline_human_summary],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=[peft_model_text_output],\n",
    "    references=[baseline_human_summary],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_1508048/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1478766500.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 6&gt;</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_1508048/1478766500.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_1508048/\u001b[0m\u001b[1;33m1478766500.py\u001b[0m:\u001b[94m6\u001b[0m in \u001b[92m<cell line: 6>\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_1508048/1478766500.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'title'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dash_line = '-'.join('' for x in range(100))\n",
    "\n",
    "index = 5670\n",
    "news = data[index]\n",
    "full_text = news['full_text']\n",
    "baseline_human_summary = news['title']\n",
    "\n",
    "# word count round off\n",
    "multiple = 5\n",
    "word_count = len(news[\"title\"].split())\n",
    "word_count = int(ceil(word_count / multiple)) * multiple\n",
    "\n",
    "start_prompt = f'Give a title to the given news article in not more than {word_count} words.\\n\\n'\n",
    "mid_prompt = '\\n\\nSummary: '\n",
    "end_prompt = '\\n\\nTitle: '\n",
    "\n",
    "prompt = start_prompt + news[\"full_text\"] + mid_prompt + news[\"summary\"] + end_prompt\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "original_model_text_output = original_tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(dash_line)\n",
    "print(f'FULL TEXT:\\n{full_text}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{baseline_human_summary}')\n",
    "print(dash_line)\n",
    "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL: {peft_model_text_output}')\n",
    "\n",
    "\n",
    "# EVALUATE\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=[original_model_text_output],\n",
    "    references=[baseline_human_summary],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=[peft_model_text_output],\n",
    "    references=[baseline_human_summary],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "name": "Fine-tune a language model",
   "provenance": []
  },
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
